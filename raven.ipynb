{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAVEN: Reducing Attributes Via Evaluating Nearness [üê¶‚Äç‚¨õ](https://en.wikipedia.org/wiki/Backronym)\n",
    "\n",
    "A convenient tool to reduce the attributes (features) of that insanely large dataset in a way that doesn't affect dataset quality. It does this by identifying clusters of linearly related (and therefore redundant) features, and only preserving the feature most 'near' to all other features.\n",
    "\n",
    "This doc shows you how and when to use Raven.\n",
    "\n",
    "\n",
    "In this example, we are using  a sample of [ClimSim](https://leap-stc.github.io/ClimSim/README.html), a huge (~377 GB) dataset containing 925 attributes. We will consider the first 556 columns to predict the 557th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    state_t_0   state_t_1   state_t_2   state_t_3   state_t_4   state_t_5  \\\n",
       " 0  215.117418  235.579037  250.793334  263.115017  262.570816  256.696740   \n",
       " 1  216.660442  236.356702  250.701147  260.185608  257.965210  254.948239   \n",
       " 2  217.766221  233.437275  242.320351  253.499835  260.342576  261.025882   \n",
       " 3  218.452505  232.471070  240.774734  253.624602  257.088679  258.302960   \n",
       " 4  217.883840  235.344818  248.610196  256.193888  255.609799  255.376257   \n",
       " \n",
       "     state_t_6   state_t_7   state_t_8   state_t_9  ...   pbuf_N2O_50  \\\n",
       " 0  248.951714  245.328685  238.121496  233.741971  ...  4.908584e-07   \n",
       " 1  247.290346  245.702725  239.636065  234.963264  ...  4.908584e-07   \n",
       " 2  254.783378  249.582744  240.681978  233.681856  ...  4.908584e-07   \n",
       " 3  251.741567  248.882723  242.147880  235.834188  ...  4.908584e-07   \n",
       " 4  247.574184  244.685004  238.785738  234.712877  ...  4.908584e-07   \n",
       " \n",
       "     pbuf_N2O_51   pbuf_N2O_52   pbuf_N2O_53   pbuf_N2O_54   pbuf_N2O_55  \\\n",
       " 0  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07   \n",
       " 1  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07   \n",
       " 2  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07   \n",
       " 3  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07   \n",
       " 4  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07   \n",
       " \n",
       "     pbuf_N2O_56   pbuf_N2O_57   pbuf_N2O_58   pbuf_N2O_59  \n",
       " 0  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  \n",
       " 1  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  \n",
       " 2  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  \n",
       " 3  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  \n",
       " 4  4.908584e-07  4.908584e-07  4.908584e-07  4.908584e-07  \n",
       " \n",
       " [5 rows x 556 columns],\n",
       " 0    1.375988e-08\n",
       " 1   -4.182312e-06\n",
       " 2   -1.149351e-05\n",
       " 3   -1.490328e-05\n",
       " 4   -9.537667e-06\n",
       " Name: ptend_t_0, dtype: float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('train1000.csv').drop(columns=['sample_id', 'Unnamed: 0'])\n",
    "x = data.iloc[:, :556] \n",
    "y = data.iloc[:, 556]\n",
    "\n",
    "x.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first train a random forest regressor on the data without using RAVEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def train(x, y, reduction_status = \"\"):\n",
    "    train_size = int(len(x) * 0.8)\n",
    "\n",
    "    x_train = x.iloc[:train_size, :]\n",
    "    y_train = y.iloc[:train_size]\n",
    "    x_test = x.iloc[train_size:, :]\n",
    "    y_test = y.iloc[train_size:]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    mse_without_reduction = mean_squared_error(y_test, y_pred)\n",
    "    r2_without_reduction = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error{reduction_status}: \", mse_without_reduction)\n",
    "    print(f\"R2 Score{reduction_status}: \", r2_without_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error without reduction:  1.712628771132408e-11\n",
      "R2 Score without reduction:  0.9795469803323228\n",
      "CPU times: total: 8.56 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(x,y, \" without reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 score looks great, but the training time is too long. For large datasets, many attributes tend to have strong correlations with others. RAVEN identifies these by calculating correlations between attribute pairs. We can speed this up by randomly sampling from the dataset.\n",
    "\n",
    "Additionally, to avoid being too lenient, we can adjust the threshold 'tau' of the correlation coefficient, which determines when RAVEN flags attributes as redundant.\n",
    "\n",
    "Let's use RAVEN with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a (relatively) short amount of time, RAVEN identifies 339 redundant features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 redundant columns identified, out of 556 columns\n",
      "63.84892086330935% Reduction\n"
     ]
    }
   ],
   "source": [
    "from raven import raven\n",
    "\n",
    "redundant = raven(x)\n",
    "print(f\"{len(redundant)} redundant columns identified, out of {len(x.columns)} columns\")\n",
    "print(f\"{len(redundant)/len(x.columns) * 100}% Reduction\")\n",
    "\n",
    "x1 = x.drop(columns=redundant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error after reduction:  1.646347956793695e-11\n",
      "R2 Score after reduction:  0.980338537044501\n",
      "CPU times: total: 3.38 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(x1, y, \" after reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty big reduction with no change in the R^2 score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
