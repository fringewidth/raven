{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVEN: A quadratic alternative to PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('train1000.csv').drop(columns=['sample_id', 'Unnamed: 0'])\n",
    "x = data.iloc[:, :556] \n",
    "y = data.iloc[:, 556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate pairs of attributes\n",
    "\n",
    "from itertools import combinations\n",
    "attributes = x.columns.tolist()\n",
    "pairs = list(combinations(attributes,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "x_sample_np = x.loc[np.random.choice(x.index, sample_size, False)].to_numpy()\n",
    "r_squared = {}\n",
    "\n",
    "for first, second in pairs:\n",
    "    first_i = x.columns.get_loc(first)\n",
    "    second_i = x.columns.get_loc(second)\n",
    "    cov_mat = np.cov(x_sample_np[:, first_i], x_sample_np[:, second_i])\n",
    "    r_squared[first + \" \" + second] = cov_mat[0, 1]**2 / cov_mat[0, 0] / cov_mat[1, 1] if all(cov_mat[i, i] != 0 for i in range(2)) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate r squared for each pair based on a sample\n",
    "\n",
    "# sample_size = 100\n",
    "# import numpy as np\n",
    "\n",
    "# sample_indices = np.random.choice(x.index, size=sample_size, replace=False)\n",
    "# x_sample_np = x.loc[sample_indices].to_numpy()\n",
    "# r_squared = {}\n",
    "\n",
    "# for i, (feature1, feature2) in enumerate(pairs):\n",
    "#     feature1_index = x.columns.get_loc(feature1)\n",
    "#     feature2_index = x.columns.get_loc(feature2)\n",
    "#     cov_matrix = np.cov(x_sample_np[:, feature1_index], x_sample_np[:, feature2_index])\n",
    "#     cov = cov_matrix[0, 1]\n",
    "#     r_squared[feature1 + \" \" + feature2] = (cov**2) / cov_matrix[0, 0] / cov_matrix[1, 1] if cov_matrix[0, 0] != 0 and cov_matrix[1, 1] != 0 else 0\n",
    "\n",
    "# # for pair in pairs:\n",
    "#     # try:\n",
    "#     #     xreg = pair[0]\n",
    "#     #     yreg = pair[1]\n",
    "\n",
    "#     #     reg = stats.linregress(x_sample[xreg],x_sample[yreg])\n",
    "#     #     r_squared[xreg + \" \" + yreg] = reg.rvalue**2\n",
    "#     # except:\n",
    "#         # continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph with the r squared values, and normalize weights\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def transform_weight(weight, min_old, max_old, min_new, max_new):\n",
    "    return (weight - min_old) / (max_old - min_old) * (max_new - min_new) + min_new\n",
    "\n",
    "def make_graph(edges, threshold=0.95):\n",
    "    G = nx.Graph()\n",
    "    for key, value in edges.items():\n",
    "        if value > threshold:\n",
    "            u, v = key.split()\n",
    "            G.add_nodes_from([u,v])\n",
    "            G.add_edge(u, v, weight=value)\n",
    "\n",
    "    for u, v, w in G.edges(data=True):\n",
    "        w['weight'] = transform_weight(w['weight'], 1, 1/threshold, 0.5, 1)\n",
    "\n",
    "    return G\n",
    "\n",
    "G = make_graph(r_squared)\n",
    "\n",
    "# list all articulation poitns in the graph\n",
    "\n",
    "# articulation_points = list(nx.articulation_points(G))\n",
    "\n",
    "# print(articulation_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 8.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For each connected component, calculate the closeness centre, visualise\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "essential_attrs = []\n",
    "\n",
    "# num_components = len(connected_components)\n",
    "# numcols = 3 \n",
    "# numrows = math.ceil(num_components / numcols)\n",
    "\n",
    "# fig, axes = plt.subplots(numrows, numcols, figsize=(numcols * 4, numrows * 4))\n",
    "# fig.tight_layout(pad=4.0)\n",
    "\n",
    "# axes = axes.flatten()\n",
    "for i, component in enumerate(connected_components):\n",
    "    subgraph = G.subgraph(component)\n",
    "    max_degree_node, _ = max(subgraph.degree(), key = lambda item: item[1])\n",
    "    essential_attrs.append(max_degree_node)\n",
    "\n",
    "    # colors = ['red' if node == closeness_center and node == max_degree_node else \n",
    "    #           'green' if node == closeness_center else \n",
    "    #           'pink' if node == max_degree_node else \n",
    "    #           'blue' for node in subgraph.nodes()]\n",
    "#     nx.draw(subgraph, ax=axes[i], with_labels=True, node_color=colors, font_size=6, node_size=15)\n",
    "#     axes[i].set_title(f\"Component {i+1} \\n closeness center: {closeness_center} \\n max degree node: {max_degree_node}\")\n",
    "\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model without removing any attributes\n",
    "\n",
    "train_size = int(len(x) * 0.8)\n",
    "\n",
    "x_train = x.iloc[:train_size, :]\n",
    "y_train = y.iloc[:train_size]\n",
    "x_test = x.iloc[train_size:, :]\n",
    "y_test = y.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error without reduction:  1.712628771132408e-11\n",
      "R2 Score without reduction:  0.9795469803323228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse_without_reduction = mean_squared_error(y_test, y_pred)\n",
    "r2_without_reduction = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error without reduction: \", mse_without_reduction)\n",
    "print(\"R2 Score without reduction: \", r2_without_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.38848920863309% Reduction\n"
     ]
    }
   ],
   "source": [
    "# train model after removing redundant attributes\n",
    "\n",
    "essential = essential_attrs\n",
    "# essential = articulation_points\n",
    "redundant = [node for node in G.nodes() if node not in essential]\n",
    "print(f\"{len(redundant)/len(x.columns) * 100}% Reduction\")\n",
    "\n",
    "x1 = x.drop(columns=redundant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1.to_csv('../KANS/train1000_raven.csv')\n",
    "# x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x1.iloc[:train_size, :]\n",
    "x_test = x1.iloc[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  1.6598681311190304e-11\n",
      "R2 Score:  0.9801770727528533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_train = y.iloc[:train_size]\n",
    "y_test = y.iloc[train_size:]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse_graph = mean_squared_error(y_test, y_pred)\n",
    "r2_graph = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse_graph)\n",
    "print(\"R2 Score: \", r2_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
