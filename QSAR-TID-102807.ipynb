{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20457641",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4697f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openML in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (1.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (2.32.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (2.3.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (1.16.2)\n",
      "Requirement already satisfied: numpy>=1.6.2 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (2.3.4)\n",
      "Requirement already satisfied: minio in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (7.2.18)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (22.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (4.67.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from openML) (25.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from pandas>=1.0.0->openML) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from pandas>=1.0.0->openML) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from python-dateutil->openML) (1.17.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from minio->openML) (25.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from minio->openML) (2025.10.5)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from minio->openML) (3.23.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from minio->openML) (4.15.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from minio->openML) (2.5.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from argon2-cffi->minio->openML) (25.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openML) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openML) (2.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from requests->openML) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from requests->openML) (3.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrey\\desktop\\raven\\venv\\lib\\site-packages (from tqdm->openML) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openML scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8a9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching OpenML dataset 3454...\n",
      "Dataset loaded: QSAR-TID-12744\n",
      "Features shape: (59, 1024)\n",
      "Target: MEDIAN_PXC50\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = 3454\n",
    "\n",
    "print(f\"Fetching OpenML dataset {DATASET_ID}...\")\n",
    "\n",
    "try:\n",
    "    # 'as_frame=False' is better for sparse data to ensure X is a matrix\n",
    "    dataset = fetch_openml(data_id=DATASET_ID, as_frame=False, parser='auto')    \n",
    "    X_raw = dataset.data   \n",
    "    y_raw = dataset.target \n",
    "\n",
    "    print(f\"Dataset loaded: {dataset.details.get('name')}\")\n",
    "    print(f\"Features shape: {X_raw.shape}\")\n",
    "    print(f\"Target: {dataset.target_names[0]}\") \n",
    "    data_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    data_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ae19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_loaded:  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "    lasso_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler(with_mean=False)), # with_mean=False is required for sparse\n",
    "        ('lasso', LassoCV(cv=5, random_state=42, n_jobs=-1, max_iter=10000))\n",
    "    ])\n",
    "    lasso_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a5cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Dataset: 3454):\n",
      "R² Score: 0.0904\n",
      "MSE: 0.9819\n",
      "MAE: 0.8628\n",
      "\n",
      "Selected 38 important features out of 1024 total.\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso_pipeline.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance (Dataset: {DATASET_ID}):\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {np.mean(np.abs(y_test - y_pred)):.4f}\")\n",
    "\n",
    "lasso_model = lasso_pipeline.named_steps['lasso']\n",
    "\n",
    "feature_names = np.array(dataset.feature_names) \n",
    "selected_features_mask = np.abs(lasso_model.coef_) > 1e-6\n",
    "selected_features = feature_names[selected_features_mask]\n",
    "    \n",
    "print(f\"\\nSelected {len(selected_features)} important features out of {X_raw.shape[1]} total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9da65",
   "metadata": {},
   "source": [
    "# RAVEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe06dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raven(data, mode='openml', sample_size=50, tau=0.95, target_col=None):\n",
    "    \"\"\"\n",
    "    Implements the Raven algorithm that identifies redundant features in a dataset.\n",
    "\n",
    "    Args: \n",
    "        data: DataFrame object, OpenML dataset ID (int), or name (str).\n",
    "        mode (str): 'openml' (default) or 'df'. \n",
    "                    Specifies how to interpret the 'data' argument.\n",
    "        tau (float): Threshold for correlation coefficient. Default is 0.95.\n",
    "        sample_size (int): Number of samples to use. Default is 50.\n",
    "        target_col (str, optional): Target column to drop.\n",
    "\n",
    "    Returns:\n",
    "        essential (list): Names of selected (non-redundant) features.\n",
    "        redundant (list): Names of redundant features.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Validate mode ---\n",
    "    if mode not in ['openml', 'df']:\n",
    "        raise ValueError(\"mode must be either 'openml' or 'df'\")\n",
    "\n",
    "    # --- Load dataset based on mode ---\n",
    "    if mode == 'openml':\n",
    "        if not isinstance(data, (int, str)):\n",
    "            raise ValueError(\"If mode='openml', data must be an OpenML dataset ID (int) or name (str).\")\n",
    "        \n",
    "        print(f\"Fetching OpenML dataset: {data}...\")\n",
    "        dataset = openml.datasets.get_dataset(data)\n",
    "        df, *_ = dataset.get_data(dataset_format=\"dataframe\")\n",
    "        if target_col is None and dataset.default_target_attribute:\n",
    "            target_col = dataset.default_target_attribute\n",
    "        if target_col and target_col in df.columns:\n",
    "            df = df.drop(columns=[target_col])\n",
    "        dataset_name = dataset.name\n",
    "\n",
    "\n",
    "    elif mode == 'df':\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"If mode='df', data must be a pandas DataFrame.\")\n",
    "        \n",
    "        df = data.copy()\n",
    "        dataset_name = \"Custom DataFrame\"\n",
    "        if target_col and target_col in df.columns:\n",
    "            # Drop target column if specified for DataFrame\n",
    "            df = df.drop(columns=[target_col])\n",
    "\n",
    "    # --- Keep only numeric columns ---\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "    total_features = len(df.columns)\n",
    "\n",
    "    # --- Validate parameters ---\n",
    "    if tau <= 0 or tau >= 1:\n",
    "        raise ValueError(\"tau must be greater than 0 and lesser than 1\")\n",
    "    if sample_size < 1:\n",
    "        raise ValueError(\"sample_size must be greater than 0\")\n",
    "    if sample_size > len(df):\n",
    "        print(f\"Warning: sample_size ({sample_size}) is larger than dataset length ({len(df)}). Using full dataset (n={len(df)}) for sampling.\")\n",
    "        sample_size = len(df)\n",
    "    if total_features < 2:\n",
    "        raise ValueError(\"DataFrame must have at least 2 numeric columns\")\n",
    "\n",
    "    # --- Convert to numpy sample ---\n",
    "    n_samples = min(sample_size, len(df))\n",
    "    sample = df.sample(n_samples, random_state=42).to_numpy()\n",
    "    r2_scores = {}\n",
    "    col_idx = {col: df.columns.get_loc(col) for col in df.columns}\n",
    "\n",
    "    # --- Compute R^2 between feature pairs ---\n",
    "\n",
    "    for first, second in combinations(df.columns, 2):\n",
    "        f_i, s_i = col_idx[first], col_idx[second]\n",
    "        cov = np.cov(sample[:, f_i], sample[:, s_i])\n",
    "        \n",
    "        denom = cov[1, 1] * cov[0, 0]\n",
    "        if denom == 0:\n",
    "            r2_scores[first, second] = 0\n",
    "        else:\n",
    "            r2_scores[first, second] = cov[1, 0]**2 / denom\n",
    "\n",
    "    # --- Build correlation graph ---\n",
    "\n",
    "    def make_graph(scores, tau):\n",
    "        def get_weight(r2): return (r2 - tau)/(1 - tau) * 0.5 + 0.5\n",
    "        G = nx.Graph()\n",
    "        for (a, b), r2 in scores.items():\n",
    "            if r2 >= tau:\n",
    "                G.add_edge(a, b, weight=get_weight(r2))\n",
    "        return G\n",
    "\n",
    "    G = make_graph(r2_scores, tau)\n",
    "    del sample, r2_scores\n",
    "\n",
    "    # --- Identify essential and redundant features ---\n",
    "\n",
    "    essential = []\n",
    "    for comp in nx.connected_components(G):\n",
    "        sub = G.subgraph(comp)\n",
    "        max_deg_node, _ = max(sub.degree(), key=lambda x: x[1])\n",
    "        essential.append(max_deg_node)\n",
    "\n",
    "    redundant = [node for node in G.nodes() if node not in essential]\n",
    "    \n",
    "    connected_features = set(G.nodes())\n",
    "    all_features = set(df.columns)\n",
    "    isolated = list(all_features - connected_features)\n",
    "    essential = essential + isolated\n",
    "\n",
    "    return essential, redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5d6f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching OpenML dataset 3454...\n",
      "Dataset loaded: 59 samples, 1024 features.\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = 3454\n",
    "print(f\"Fetching OpenML dataset {DATASET_ID}...\")\n",
    "\n",
    "try:\n",
    "    dataset = fetch_openml(data_id=DATASET_ID, as_frame=False, parser='auto')\n",
    "    X_raw = dataset.data\n",
    "    y_raw = dataset.target\n",
    "    feature_names = np.array(dataset.feature_names)\n",
    "    print(f\"Dataset loaded: {X_raw.shape[0]} samples, {X_raw.shape[1]} features.\")\n",
    "    data_loaded = True\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    data_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9aec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected sparse matrix — converting to dense DataFrame for Raven...\n"
     ]
    }
   ],
   "source": [
    "if data_loaded:\n",
    "    if issparse(X_raw):\n",
    "        print(\"Detected sparse matrix — converting to dense DataFrame for Raven...\")\n",
    "        X_dense_df = pd.DataFrame(X_raw.toarray(), columns=feature_names)\n",
    "    else:\n",
    "        print(\"Detected dense NumPy array — creating DataFrame directly.\")\n",
    "        X_dense_df = pd.DataFrame(X_raw, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9365ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: sample_size (200) is larger than dataset length (59). Using full dataset (n=59) for sampling.\n",
      "Raven selected 744 essential features out of 1024.\n"
     ]
    }
   ],
   "source": [
    "essential_features, redundant_features = raven(\n",
    "        data=X_dense_df,\n",
    "        mode='df',\n",
    "        sample_size=200,  \n",
    "        tau=0.95\n",
    ")\n",
    "print(f\"Raven selected {len(essential_features)} essential features out of {len(feature_names)}.\")\n",
    "X_selected = X_dense_df[essential_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f86c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_raw, test_size=0.2, random_state=42)\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f136af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "\n",
      "---Results ---\n",
      "R² Score: 0.3229\n",
      "MSE: 0.7309\n",
      "MAE: 0.7498\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "print(\"\\n---Results ---\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b2cbf",
   "metadata": {},
   "source": [
    "# BASE MODEL (without raven or lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f69835f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dense_df, y_raw, test_size=0.2, random_state=42)\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae5b476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "\n",
      "---Results ---\n",
      "R² Score: 0.3005\n",
      "MSE: 0.7552\n",
      "MAE: 0.7753\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "print(\"\\n---Results ---\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
